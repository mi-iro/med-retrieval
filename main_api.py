import uvicorn
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import Optional, List, Dict
import json
import numpy as np
import sys
import time

# 从我们准备好的模块中导入核心功能
# from query_generator import generate_queries_for_question
from retriever import Retriever

# --- FastAPI应用初始化 ---
app = FastAPI(
    title="Intelligent Query Processing Service (Dynamic Parameters)",
    description="A service that accepts a user question with dynamic 'topk' and 'n_queries' parameters, generates targeted sub-queries, retrieves relevant documents, and returns the consolidated results with performance metrics.",
    version="2.3.0", # Version updated for batch support
)

# --- 定义API的请求和响应模型 ---

# 原有模型 (保持不变)
class QueryRequest(BaseModel):
    question: str = Field(
        ..., 
        min_length=1,
        example="Proof of concept study: does fenofibrate have a role in sleep apnoea syndrome?"
    )
    topk: Optional[int] = Field(
        default=10, 
        gt=0, 
        le=50, 
        description="The number of documents to retrieve for each query."
    )
    n_queries: Optional[int] = Field(
        default=3, 
        gt=0, 
        le=5, 
        description="The maximum number of queries to generate for each data source."
    )
    adaptive: Optional[bool] = Field(
        default=False,
        description="Enable adaptive retrieval mode, which uses the original question to search across all text sources and reranks them together. If true, 'n_queries' is ignored."
    )

class PerformanceMetrics(BaseModel):
    query_planning_seconds: float = Field(..., description="Time taken for the query generation phase.")
    retrieval_seconds: float = Field(..., description="Time taken for the document retrieval phase.")
    rerank_seconds: float = Field(..., description="Time taken for the document reranking phase.")
    average_rerank_score: Optional[float] = Field(None, description="The average rerank score of all retrieved documents.")

class ApiResponse(BaseModel):
    parameters_used: dict = Field(..., description="The parameters (topk, n_queries, adaptive, question) used for this request.")
    performance_metrics: PerformanceMetrics = Field(..., description="Performance metrics for the request.")
    generated_queries: list = Field(..., description="The list of structured queries generated by the LLM.")
    retrieved_documents: list = Field(..., description="The list of documents retrieved based on the generated queries.")

# --- 新增：批量自适应检索的请求和响应模型 ---
class BatchQueryRequest(BaseModel):
    question: List[str] = Field(
        ...,
        min_length=1,
        example=["Parkinson", "Headache", "Diabetes"]
    )
    topk: Optional[int] = Field(
        default=3,
        gt=0,
        le=50,
        description="The number of documents to retrieve for each query."
    )

class BatchApiResponse(BaseModel):
    results: List[ApiResponse] = Field(..., description="A list of results, one for each question in the batch request.")


# --- API 端点定义 ---

# 原有端点 (保持不变)
@app.post("/process-query/", response_model=ApiResponse)
async def process_query_endpoint(request: QueryRequest):
    """
    接收一个用户问题及可选参数，执行两步流程，并返回详细的性能指标：
    1.  **生成查询 (可跳过)**: 将问题发送给大语言模型，创建结构化查询。在自适应模式下此步骤被跳过。
    2.  **检索与重排**: 使用生成的查询（或原始问题）检索并重排文档。
    
    返回内容包括生成的查询、检索到的文档，以及各阶段耗时和平均重排分数。
    """
    try:
        source_and_queries = []
        planning_time = 0.0

        if request.adaptive:
            print(f"Adaptive mode enabled for question: \"{request.question}\"")
            source_and_queries = [["adaptive_text", [request.question]]]
            planning_time = 0.0
            print("Skipping query generation.")
        else:
            print(f"Generating up to {request.n_queries} queries per source for question: \"{request.question}\"")
            start_time = time.time()
            source_and_queries, planning_time = generate_queries_for_question(request.question, n_queries=request.n_queries)
            end_time = time.time()
            planning_time = end_time - start_time
            print(f"Generated queries successfully in {planning_time:.4f} seconds:")
            print(json.dumps(source_and_queries, indent=2))

        print(f"Retrieving top {request.topk} documents...")
        retriever_instance = Retriever(topk=request.topk)
        retrieved_docs, search_timing = retriever_instance.run(source_and_queries, adaptive=request.adaptive)
        print("Documents retrieved successfully.")

        all_scores = []
        for doc_group in retrieved_docs:
            if 'results' in doc_group:
                for doc in doc_group['results']:
                    if 'rerank_score' in doc:
                        all_scores.append(doc['rerank_score'])
        
        avg_rerank_score = np.mean(all_scores) if all_scores else None

        return {
            "parameters_used": {
                "topk": request.topk,
                "n_queries": request.n_queries,
                "adaptive": request.adaptive,
                "question": request.question
            },
            "performance_metrics": {
                "query_planning_seconds": planning_time,
                "retrieval_seconds": search_timing.get("retrieval_time_seconds", 0),
                "rerank_seconds": search_timing.get("rerank_time_seconds", 0),
                "average_rerank_score": avg_rerank_score
            },
            "generated_queries": source_and_queries,
            "retrieved_documents": retrieved_docs
        }

    except ValueError as e:
        print(f"An error occurred during retrieval: {e}")
        raise HTTPException(status_code=500, detail=f"An error occurred during the retrieval process: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        raise HTTPException(status_code=500, detail=f"An unexpected server error occurred: {e}")

# --- 新增：批量处理的API端点 ---
@app.post("/process-batch-query/", response_model=BatchApiResponse, summary="Process a batch of questions with adaptive retrieval")
async def process_batch_query_endpoint(request: BatchQueryRequest):
    """
    接收一个问题列表，为每个问题执行并行的自适应检索，并返回所有结果的集合。
    该模式下，系统会跳过查询生成步骤，直接使用原始问题在所有文本源中进行搜索。
    """
    try:
        # 1. 准备 retriever 的输入格式
        # 格式为: [["adaptive_text", ["问题一", "问题二", ...]]]
        source_and_queries = [["adaptive_text", request.question]]
        questions_count = len(request.question)
        print(f"Batch adaptive mode enabled for {questions_count} questions.")

        # 2. 创建Retriever实例并调用，获取文档和计时信息
        print(f"Retrieving top {request.topk} documents for each question...")
        retriever_instance = Retriever(topk=request.topk)
        # 调用run时 adaptive=False, 复用其内部能处理多个query的逻辑分支
        retrieved_docs, search_timing = retriever_instance.run(source_and_queries, adaptive=False)
        print("Batch documents retrieved successfully.")

        # 3. 为每个问题组织响应
        all_results = []
        total_docs_count = len(retrieved_docs)

        # 确保返回的文档组数量与问题数量匹配
        if total_docs_count != questions_count:
            raise HTTPException(
                status_code=500,
                detail=f"Mismatch between number of questions ({questions_count}) and retrieved document groups ({total_docs_count})."
            )

        # 总的检索和重排时间
        total_retrieval_time = search_timing.get("retrieval_time_seconds", 0)
        total_rerank_time = search_timing.get("rerank_time_seconds", 0)

        for i, q in enumerate(request.question):
            doc_group = retrieved_docs[i]
            all_scores = []
            if 'results' in doc_group:
                for doc in doc_group['results']:
                    if 'rerank_score' in doc:
                        all_scores.append(doc['rerank_score'])
            
            avg_rerank_score = np.mean(all_scores) if all_scores else None
            
            # 因为时间是整个批次的总和，这里将其分配到每个项目以符合单一响应的格式
            # 注意: 这只是为了格式统一，实际时间是批处理的总时间
            single_item_response = {
                "parameters_used": {
                    "topk": request.topk,
                    "n_queries": "N/A (Batch Adaptive Mode)",
                    "adaptive": True,
                    "question": q
                },
                "performance_metrics": {
                    "query_planning_seconds": 0.0,
                    "retrieval_seconds": total_retrieval_time,
                    "rerank_seconds": total_rerank_time,
                    "average_rerank_score": avg_rerank_score
                },
                # 生成的查询就是自适应查询本身
                "generated_queries": [["adaptive_text", [q]]],
                "retrieved_documents": [doc_group]
            }
            all_results.append(ApiResponse.model_validate(single_item_response))

        # 4. 构造并返回批处理响应
        return {"results": all_results}

    except ValueError as e:
        print(f"An error occurred during retrieval: {e}")
        raise HTTPException(status_code=500, detail=f"An error occurred during the retrieval process: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        raise HTTPException(status_code=500, detail=f"An unexpected server error occurred: {e}")

@app.get("/", summary="Health Check")
def read_root():
    """
    提供一个简单的端点，用于检查服务是否正在运行。
    """
    return {"status": "ok", "message": "Query Processing Service is running."}

# --- 运行服务器 ---
if __name__ == "__main__":
    assert len(sys.argv) > 1, "PORT?"
    port = int(sys.argv[1])
    uvicorn.run(app, host="0.0.0.0", port=port)